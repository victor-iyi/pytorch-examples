{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full CIFAR10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full CIFAR10\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters.\n",
    "\n",
    "\n",
    "# image channel 3=RGB, 1=Grayscale\n",
    "img_channels = 3\n",
    "\n",
    "# Class labels.\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "num_classes = len(classes)\n",
    "\n",
    "# Data directory.\n",
    "data_dir = '../datasets'  # Dataset directory.\n",
    "download = True           # Download dataset iff not already downloaded.\n",
    "normalize = True          # Maybe normalize training data.\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 16  # Mini-batch size.\n",
    "lr = 1e-2        # Optimizer's learning rate.\n",
    "epochs = 4       # Number of full passes over entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Should normalize images or not.\n",
    "# Normalization helps convergence.\n",
    "if normalize:\n",
    "    # Transform rule: Convert to Tensor, Normalize images in range -1 to 1.\n",
    "    transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5), \n",
    "                                                         (0.5, 0.5, 0.5))])\n",
    "else:\n",
    "    # Transform rule: Convert to Tensor without normalizing image\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Download the training set and apply the transform rule to each.\n",
    "trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=download, transform=transform)\n",
    "# Load the training set into mini-batches and shuffle them\n",
    "trainset = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "# Download the testing set and apply the transform rule to each.\n",
    "testset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=download, transform=transform)\n",
    "# Load the testing set into mini-batches without shuffling.\n",
    "testset = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization function to visualize dataset.\n",
    "def visualize(data, title='Visualization', smooth=False):\n",
    "    # Iterate over the data.\n",
    "    data_iter = iter(data)\n",
    "    # Unpack images and labels.\n",
    "    images, labels = data_iter.next()\n",
    "    # Free up memory\n",
    "    del data_iter\n",
    "    # Join labels separated by spaces.\n",
    "    labels = ' '.join(classes[label] for label in labels)\n",
    "    # Call to helper function for plotting images.\n",
    "    imshow(images, title=title, smooth=smooth)\n",
    "    # Print out the labels.\n",
    "    print('{} labels: {}'.format(title, labels))\n",
    "\n",
    "\n",
    "# Helper function for plotting images.\n",
    "def imshow(img, title, smooth=False):\n",
    "    # Concatenate images into grids.\n",
    "    img = torchvision.utils.make_grid(img)\n",
    "    # Unnormalize image as necessary.\n",
    "    img = img/2+0.5 if normalize else img\n",
    "    # Interpolation parameters for image smoothening.\n",
    "    smooth = 'bicubic' if smooth else 'spline16'\n",
    "    # Convert the images to a numpy array.\n",
    "    np_img = img.numpy()\n",
    "    # Plot images\n",
    "    plt.imshow(np.transpose(np_img, [1, 2, 0]), interpolation=smooth)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_images(images, labels, pred=None, smooth=True):\n",
    "    images = images / 2 + 0.5 if normalize else images\n",
    "    # Create figure with sub-plots.\n",
    "    fig, axes = plt.subplots(4, 4)\n",
    "\n",
    "    # Adjust vertical spacing if we need to print ensemble and best-net.\n",
    "    wspace, hspace = 0.3, 0.6 if pred else 0.3\n",
    "    fig.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Interpolation type.\n",
    "        smooth = 'spline16' if smooth else 'nearest'\n",
    "\n",
    "        # Plot image.\n",
    "        ax.imshow(np.transpose(images[i], (1, 2, 0)), interpolation=smooth)\n",
    "            \n",
    "        # Name of the true class.\n",
    "        labels_name = classes[labels[i]]\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if pred is None:\n",
    "            xlabel = f'True: {labels_name}'\n",
    "        else:\n",
    "            # Name of the predicted class.\n",
    "            pred_name = classes[pred[i]]\n",
    "            \n",
    "            xlabel = f'True: {labels_name}\\nPred: {pred_name}'\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Let's visualize some training set.\n",
    "# visualize(trainset, title='Training set', smooth=True)\n",
    "train_iter = iter(trainset)\n",
    "images, labels = train_iter.next()\n",
    "plot_images(images, labels=labels, smooth=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        # Hyper-parameters\n",
    "        self._img_channels = kwargs.get('img_channels')\n",
    "        self._num_classes = kwargs.get('num_classes')\n",
    "        \n",
    "        # 2 convolutional & 3 fully connected layers\n",
    "        self.conv1 = nn.Conv2d(self._img_channels, 16, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 2)\n",
    "        flatten_size = self.conv2.out_channels * 7 * 7\n",
    "        self.fc1 = nn.Linear(flatten_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, self._num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        # Flatten layer\n",
    "        x = x.view(-1, self._flatten(x))\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))     # relu + linear\n",
    "        x = F.dropout(x, p=0.2)     # 20% dropout\n",
    "        x = F.relu(self.fc2(x))     # relu + linear\n",
    "        # Output layer\n",
    "        x = F.sigmoid(self.fc3(x))  # sigmoid + linear\n",
    "        return x\n",
    "    \n",
    "    def _flatten(self, x):\n",
    "        size = x.size()[1:]  # input shape excluding batch dim.\n",
    "        return torch.Tensor(size).numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(img_channels=img_channels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for i, data in enumerate(trainset):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        # Clear the optimizer's gradient buffer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward + loss \n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()  # Back propagate\n",
    "        \n",
    "        # Updates learnable params\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f'\\rEpoch: {epoch+1:,}\\tIter: {i+1:,}\\tLoss: {loss.data[0]:.4f}', end='')\n",
    "    print()\n",
    "print('Finished training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at some test data\n",
    "visualize(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make some predictions with the testset\n",
    "test_iter = iter(testset)\n",
    "images, labels = test_iter.next()\n",
    "\n",
    "# Convert images to `autograd.Variable` before \n",
    "# passing through the network.\n",
    "output = net(Variable(images))\n",
    "print(output.data)\n",
    "\n",
    "# Take the argmax of the predicted output\n",
    "_, predictions = torch.max(output.data, dim=1)\n",
    "\n",
    "# Visualize the predictions\n",
    "imshow(images, title='Network predictions', smooth=True)\n",
    "pred_labels = ' '.join(classes[pred] for pred in predictions)\n",
    "print(f'Network prediction labels: {pred_labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The performance for each class\n",
    "correct_class = torch.zeros(len(classes))\n",
    "total_class = torch.zeros(len(classes))\n",
    "\n",
    "for data in testset:\n",
    "    images, labels = data\n",
    "    output = net(Variable(images))\n",
    "    _, predictions = torch.max(output.data, dim=1)\n",
    "    correct = (predictions == labels).squeeze()\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        correct_class += correct[i]\n",
    "        total_class += 1\n",
    "\n",
    "accuracy = correct_class / total_class\n",
    "accuracy, _ = torch.sort(accuracy, descending=True)\n",
    "\n",
    "for i, acc in enumerate(accuracy):\n",
    "    print(f'Accuracy for {classes[i]} \\t = {acc:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
