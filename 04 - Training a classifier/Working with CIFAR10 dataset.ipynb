{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working With The CIFAR10 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is it. You've seen how to define a simple convolutional neural network, compute loss w.r.t. the graph Variables, and make gradient updates manually and with `torch.nn.optim` package.\n",
    "Now you might be thinking:\n",
    "\n",
    "### What about the data?\n",
    "\n",
    "Generally, when you have to deal with image, text, audio or video data, you can use standard python packages that load data into a numpy array. Then you can convert this array into a `torch.*Tensor`.\n",
    "\n",
    "- For images, packages such as `Pillow`, `OpenCV` are useful.\n",
    "- For audio, packages such as `scipy` and `librosa`.\n",
    "- For text, either raw Python or Cython based loading, or `NLTK` and `SpaCy` are useful.\n",
    "\n",
    "Specifically for [Computer vision](), the creators of pytorch have generously created a package called `torchvision`, that has data loaders for common datasets such as Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz., `torchvision.datasets` and `torch.utils.data.DataLoader`. This provides a huge convinence from writing boiler plate code.\n",
    "\n",
    "We will use the **CIFAR10 dataset**. It has the classes: *‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’*. The images in CIFAR-10 are of size `3x32x32`, i.e. 3-channel color images of `32x32` pixels in size.\n",
    "\n",
    "![CIFAR10 Dataset](../images/cifar10.png)\n",
    "\n",
    "### Training an image classifier\n",
    "\n",
    "We will do the following steps in order:\n",
    "\n",
    "1. Load and normalizing the CIFAR10 training and test datasets using `torchvision`.\n",
    "2. Define a Convolution Neural Network.\n",
    "3. Define a loss function.\n",
    "4. Train the network on the training data.\n",
    "5. Test the network on the test data.\n",
    "\n",
    "#### 1. Loading and normalizing CIFAR10\n",
    "Using `torchvision`, it’s extremely easy to load CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# file manipulation\n",
    "import os.path\n",
    "\n",
    "# arrays and visualization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pytorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Special package provided by pytorch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some *Hyperparameters* we're gonna need later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters.\n",
    "\n",
    "\n",
    "# image channel 3=RGB, 1=Grayscale\n",
    "img_channels = 3\n",
    "\n",
    "# Class labels.\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "num_classes = len(classes)\n",
    "\n",
    "# Data directory.\n",
    "data_dir = '../datasets'  # Dataset directory.\n",
    "download = True           # Download dataset iff not already downloaded.\n",
    "normalize = True          # Maybe normalize training data.\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 16  # Mini-batch size.\n",
    "lr = 1e-2        # Optimizer's learning rate.\n",
    "epochs = 4       # Number of full passes over entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the `torchvision` dataset are PILImage images of range [0, 1]. We transform them to Tensors of normalized range [-1, 1].\n",
    "\n",
    "Define the data directory, i.e. where the data should be downloaded to. With the use of `os.path` module.\n",
    "\n",
    "**NOTE:** `data_dir` could be modified to fit your use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should normalize images or not.\n",
    "# Normalization helps convergence.\n",
    "if normalize:\n",
    "    # Transform rule: Convert to Tensor, Normalize images in range -1 to 1.\n",
    "    transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5), \n",
    "                                                         (0.5, 0.5, 0.5))])\n",
    "else:\n",
    "    # Transform rule: Convert to Tensor without normalizing image\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Download the training set and apply the transform rule to each.\n",
    "trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=download, transform=transform)\n",
    "# Load the training set into mini-batches and shuffle them\n",
    "trainset = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "# Download the testing set and apply the transform rule to each.\n",
    "testset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=download, transform=transform)\n",
    "# Load the testing set into mini-batches without shuffling.\n",
    "testset = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Helper function to plot images and labels\n",
    "def imshow(images, labels, pred=None, smooth=True):\n",
    "    images = images / 2 + 0.5 if normalize else images\n",
    "    # Create figure with sub-plots.\n",
    "    fig, axes = plt.subplots(4, 4)\n",
    "\n",
    "    # Adjust vertical spacing if we need to print ensemble and best-net.\n",
    "    wspace, hspace = 0.2, 0.8 if pred is not None else 0.4\n",
    "    fig.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Interpolation type.\n",
    "        smooth = 'spline16' if smooth else 'nearest'\n",
    "\n",
    "        # Plot image.\n",
    "        ax.imshow(np.transpose(images[i], (1, 2, 0)), interpolation=smooth)\n",
    "            \n",
    "        # Name of the true class.\n",
    "        labels_name = classes[labels[i]]\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if pred is None:\n",
    "            xlabel = f'True: {labels_name}'\n",
    "        else:\n",
    "            # Name of the predicted class.\n",
    "            pred_name = classes[pred[i]]\n",
    "            \n",
    "            xlabel = f'True: {labels_name}\\nPred: {pred_name}'\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualization function to visualize dataset.\n",
    "def visualize(data, smooth=False):\n",
    "    # Iterate over the data.\n",
    "    data_iter = iter(data)\n",
    "    \n",
    "    # Unpack images and labels.\n",
    "    images, labels = data_iter.next()\n",
    "    \n",
    "    # Free up memory\n",
    "    del data_iter\n",
    "    \n",
    "    # Call to helper function for plotting images.\n",
    "    imshow(images, labels=labels, smooth=smooth)\n",
    "\n",
    "\n",
    "\n",
    "# Let's visualize some training set.\n",
    "visualize(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define a Convolution Neural Network\n",
    "\n",
    "It's time to define our neural network. You've already seen how to define a simple convolutional neural network in the last section. But this time, instead of a single color channel, we have 3-color channels, because the CIFAR10 dataset contains colored images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        # Hyper-parameters\n",
    "        self._img_channels = kwargs.get('img_channels')\n",
    "        self._num_classes = kwargs.get('num_classes')\n",
    "        \n",
    "        # 2 convolutional & 3 fully connected layers\n",
    "        self.conv1 = nn.Conv2d(self._img_channels, 16, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 2)\n",
    "        flatten_size = self.conv2.out_channels * 7 * 7\n",
    "        self.fc1 = nn.Linear(flatten_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, self._num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        # Flatten layer\n",
    "        x = x.view(-1, self._flatten(x))\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))     # relu + linear\n",
    "        x = F.dropout(x, p=0.2)     # 20% dropout\n",
    "        x = F.relu(self.fc2(x))     # relu + linear\n",
    "        # Output layer\n",
    "        x = self.fc3(x)             # linear\n",
    "        return x\n",
    "    \n",
    "    def _flatten(self, x):\n",
    "        size = x.size()[1:]  # input shape excluding batch dim.\n",
    "        return torch.Tensor(size).numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the network and pass in our parameters.\n",
    "net = Network(img_channels=img_channels, num_classes=len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define a Loss function and optimizer\n",
    "\n",
    "Let’s use a Classification Cross-Entropy loss and Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function criterion\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "# Adam optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the Network\n",
    "\n",
    "This is when things start to get interesting. We simply have to loop over our data iterator, and feed the inputs to the network and optimize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the data multiple times.\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Loop through the training dataset (batch by batch).\n",
    "    for i, data in enumerate(trainset):\n",
    "        \n",
    "        # Get the inputs and labels.\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Wrap them in Variable (explained in section 2).\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        # Zero the optimizer gradient buffer\n",
    "        # to prevent gradient accumulation.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward and backward propagation.\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update learnable parameters w.r.t the loss.\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print statistics.\n",
    "        print(f'\\rEpoch: {epoch+1:,}\\tIter: {i+1:,}\\tLoss: {loss.data[0]:.4f}', end='')\n",
    "\n",
    "    # Line break.\n",
    "    print()\n",
    "\n",
    "\n",
    "print('\\nFinished training!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test the network on the test data\n",
    "\n",
    "We have trained the network for 5 epochs (passes over the training data). Let's check if the network has learnt anything.\n",
    "\n",
    "How we check this is by comparing the ground-truth labels over the one the network predicted. We'll keep track of the ones predicted correctly by creating a list, and appending to the list if the prediction was the same as the ground-truth.\n",
    "\n",
    "Alright, that been said, let's familarize ourselves with the data one more time by plotting a few from the `testset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at some test data.\n",
    "visualize(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let's make some predictions with our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make some predictions on the testset.\n",
    "test_iter = iter(testset)\n",
    "images, labels = test_iter.next()\n",
    "\n",
    "# Convert images to `autograd.Variable` \n",
    "# before passing through the network.\n",
    "output = net(Variable(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs are \"energies\" for the 10 classes. *Higher the energy for a class, the more the network thinks that the image is of the particular class*. So, let’s get the index of the highest energy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# torch.max returns a tuple: (value, index)\n",
    "# Take the argmax of the predicted output.\n",
    "_, predictions = torch.max(output.data, dim=1)\n",
    "\n",
    "# Visualize the predictions.\n",
    "imshow(images, labels=labels, pred=predictions, smooth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe not so bad, huh? Let's see how the result performs on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of correct prediction and total.\n",
    "correct, total = 0, 0\n",
    "\n",
    "# Looping through the testset.\n",
    "for data in testset:\n",
    "    \n",
    "    # Unpack the images and labels\n",
    "    # from each mini-batch.\n",
    "    images, labels = data\n",
    "    \n",
    "    # Pass image through the network\n",
    "    # to make predictions.\n",
    "    outputs = net(Variable(images))\n",
    "    \n",
    "    # Pretrieve the index with maximum score.\n",
    "    _, pred = torch.max(outputs.data, dim=1)\n",
    "    \n",
    "    # Get the batch size and add on to the total.\n",
    "    total += labels.size(0)\n",
    "    \n",
    "    # Count the number of correct predictions.\n",
    "    # pred == outputs means where the predictions\n",
    "    # equals to the ground-truth.\n",
    "    correct += (pred == labels).sum()\n",
    "\n",
    "\n",
    "# Print the accuracy on the testset.\n",
    "print('Accuracy on testset = {:.2%}'.format(correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that's slightly better than random guessing, which is 10% accuracy (randomly picking a class out of 10 classes). Seems like the network learnt something.\n",
    "\n",
    "Hmmm, what are the classes that performed well, and the classes that did not perform well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Each index in the `correct_class` stores\n",
    "# the correct classification for that class;\n",
    "# while `total_class` stores the total number\n",
    "# of times we go through the class.\n",
    "correct_class = torch.zeros(10)\n",
    "total_class = torch.zeros(10)\n",
    "\n",
    "# Loop through all dataset\n",
    "# one batch at a time.\n",
    "for data in testset:\n",
    "    # Get the current batch images and labels\n",
    "    images, labels = data\n",
    "    \n",
    "    # Pass the images through the network\n",
    "    outputs = net(Variable(images))\n",
    "    \n",
    "    # Take the index of the maximum scores\n",
    "    # returned by the network.\n",
    "    _, pred = torch.max(outputs.data, dim=1)\n",
    "    \n",
    "    # Where the pred equals the labels will\n",
    "    # return 1; and 0 otherwise.\n",
    "    correct = (pred == labels).squeeze()\n",
    "    \n",
    "    # Loop through the batch labels\n",
    "    for i, label in enumerate(labels):\n",
    "        # Add on the correct predictions\n",
    "        # and total for the current label.\n",
    "        correct_class[label] += correct[i]\n",
    "        total_class[label] += 1\n",
    "\n",
    "\n",
    "# Calculate accuracy and sort in descending order\n",
    "accuracy = correct_class / total_class\n",
    "accuracy, _ = torch.sort(accuracy, descending=True)\n",
    "\n",
    "for i, acc in enumerate(accuracy):\n",
    "    print(f'Accuracy of {classes[i]} \\t = {acc:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
