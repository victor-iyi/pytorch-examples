{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working With The CIFAR10 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is it. You've seen how to define a simple convolutional neural network, compute loss w.r.t. the graph Variables, and make gradient updates manually and with `torch.nn.optim` package.\n",
    "Now you might be thinking:\n",
    "\n",
    "### What about the data?\n",
    "\n",
    "Generally, when you have to deal with image, text, audio or video data, you can use standard python packages that load data into a numpy array. Then you can convert this array into a `torch.*Tensor`.\n",
    "\n",
    "- For images, packages such as `Pillow`, `OpenCV` are useful.\n",
    "- For audio, packages such as `scipy` and `librosa`.\n",
    "- For text, either raw Python or Cython based loading, or `NLTK` and `SpaCy` are useful.\n",
    "\n",
    "Specifically for [Computer vision](), the creators of pytorch have generously created a package called `torchvision`, that has data loaders for common datasets such as Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz., `torchvision.datasets` and `torch.utils.data.DataLoader`. This provides a huge convinence from writing boiler plate code.\n",
    "\n",
    "We will use the **CIFAR10 dataset**. It has the classes: *‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’*. The images in CIFAR-10 are of size `3x32x32`, i.e. 3-channel color images of `32x32` pixels in size.\n",
    "\n",
    "![CIFAR10 Dataset](../images/cifar10.png)\n",
    "\n",
    "### Training an image classifier\n",
    "\n",
    "We will do the following steps in order:\n",
    "\n",
    "1. Load and normalizing the CIFAR10 training and test datasets using `torchvision`.\n",
    "2. Define a Convolution Neural Network.\n",
    "3. Define a loss function.\n",
    "4. Train the network on the training data.\n",
    "5. Test the network on the test data.\n",
    "\n",
    "#### 1. Loading and normalizing CIFAR10\n",
    "Using `torchvision`, it’s extremely easy to load CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# file manipulation\n",
    "import os.path\n",
    "\n",
    "# arrays and visualization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pytorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Special package provided by pytorch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some *Hyperparameters* we're gonna need later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download parameters\n",
    "data_dir = '../datasets'\n",
    "\n",
    "# class labels\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Image channels 3 = RGB; 1 = Grayscale image.\n",
    "img_channels = 3\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 4    # Mini-batch size\n",
    "epochs = 4        # No of passes over the training data\n",
    "lr = 1e-2         # Learning rate used by optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the `torchvision` dataset are PILImage images of range [0, 1]. We transform them to Tensors of normalized range [-1, 1].\n",
    "\n",
    "Define the data directory, i.e. where the data should be downloaded to. With the use of `os.path` module.\n",
    "\n",
    "**NOTE:** `data_dir` could be modified to fit your use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform rule => Convert to a torch.Tensor and normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), \n",
    "                                                     (0.5, 0.5, 0.5))])\n",
    "# Transform rule => Convert to torch.Tensor only\n",
    "# transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Download the dataset and apply the above transform rule.\n",
    "trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, \n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root=data_dir, train=False, \n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "# Dataset loaders: split into mini-batches, shuffle, etc.\n",
    "trainset = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testset = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's visualize the data\n",
    "# Helper function to visualize data.\n",
    "def imshow(img, title=None, smooth=False):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    np_img = img.numpy()\n",
    "    smooth = 'bicubic' if smooth else 'spline16'\n",
    "    plt.title(title if title else 'Image(s)')\n",
    "    plt.imshow(np.transpose(np_img, (1, 2, 0)), interpolation=smooth)\n",
    "\n",
    "# Get random training images\n",
    "train_iter = iter(trainset)\n",
    "images, labels = train_iter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images), title='Train images', smooth=True)\n",
    "\n",
    "# print labels\n",
    "print('Labels: {}'.format(' '.join(classes[l] for l in labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define a Convolution Neural Network\n",
    "\n",
    "It's time to define our neural network. You've already seen how to define a simple convolutional neural network in the last section. But this time, instead of a single color channel, we have 3-color channels, because the CIFAR10 dataset contains colored images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        # Hyper-parameters\n",
    "        self._img_channels = kwargs.get('img_channels', 3)\n",
    "        self._num_classes = kwargs.get('num_classes', 10)\n",
    "        \n",
    "        # 2 convolutional & 3 fully connected layers\n",
    "        self.conv1 = nn.Conv2d(self._img_channels, 16, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 2)\n",
    "        flatten_size = self.conv2.out_channels * 7 * 7\n",
    "        self.fc1 = nn.Linear(flatten_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, self._num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        # Flatten layer\n",
    "        x = x.view(-1, self._flatten(x))\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))     # relu + linear\n",
    "        x = F.dropout(x, p=0.8)     # 80% dropout\n",
    "        x = F.relu(self.fc2(x))     # relu + linear\n",
    "        # Output layer\n",
    "        x = self.fc3(x)             #  linear\n",
    "        return x\n",
    "    \n",
    "    def _flatten(self, x):\n",
    "        size = x.size()[1:]  # input shape excluding batch dim.\n",
    "        return torch.Tensor(size).numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the network and pass in our parameters\n",
    "net = Network(img_channels=img_channels, num_classes=len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define a Loss function and optimizer\n",
    "\n",
    "Let’s use a Classification Cross-Entropy loss and Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function criterion\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "# Adam optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the Network\n",
    "\n",
    "This is when things start to get interesting. We simply have to loop over our data iterator, and feed the inputs to the network and optimize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):  # loop over the data multiple times\n",
    "\n",
    "    # loop through the training dataset (batch by batch)\n",
    "    for i, data in enumerate(trainset, 0):\n",
    "        # get the inputs and labels\n",
    "        inputs, labels = data\n",
    "        # wrap them in Variable (explain in section 2.)\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        # zero the optimizer gradient buffer\n",
    "        # to prevent gradient accumulation.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimizer\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        print(f'\\rEpoch: {epoch+1:,}\\tIter: {i+1:,}\\tLoss: {loss.data[0]:.4f}', end='')\n",
    "    print()  # line break\n",
    "\n",
    "\n",
    "print('\\nFinished training!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test the network on the test data\n",
    "\n",
    "We have trained the network for 5 epochs (passes over the training data). Let's check if the network has learnt anything.\n",
    "\n",
    "How we check this is by comparing the ground-truth labels over the one the network predicted. We'll keep track of the ones predicted correctly by creating a list, and appending to the list if the prediction was the same as the ground-truth.\n",
    "\n",
    "Alright, that been said, let's familarize ourselves with the data one more time by plotting a few from the `testset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the testset.\n",
    "test_iter = iter(testset)\n",
    "# Store each batch in the respective variables.\n",
    "images, labels = test_iter.next()\n",
    "\n",
    "# Plot a few images.\n",
    "imshow(torchvision.utils.make_grid(images), title='Test images', smooth=True)\n",
    "# Class labels.\n",
    "print('Ground-truth: {}'.format(' '.join([classes[l] for l in labels])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let's make some predictions with our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions after training.\n",
    "outputs = net(Variable(images))\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs are \"energies\" for the 10 classes. *Higher the energy for a class, the more the network thinks that the image is of the particular class*. So, let’s get the index of the highest energy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# torch.max returns a tuple: (value, index)\n",
    "_, predicted = torch.max(outputs.data, dim=1)\n",
    "\n",
    "print('Prediction: {}'.format(' '.join([classes[p] for p in predicted])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe not so bad, huh? Let's see how the result performs on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of correct prediction and total.\n",
    "correct, total = 0, 0\n",
    "\n",
    "# Looping through the testset.\n",
    "for data in testset:\n",
    "    # Unpack the images and labels\n",
    "    # from each mini-batch\n",
    "    images, labels = data\n",
    "    # Pass image through the network\n",
    "    # to make predictions.\n",
    "    outputs = net(Variable(images))\n",
    "    # Pretrieve the index with maximum score\n",
    "    _, pred = torch.max(outputs.data, dim=1)\n",
    "    # Get the batch size and add on to the total\n",
    "    total += labels.size(0)\n",
    "    # Count the number of correct predictions.\n",
    "    # pred == outputs means where the predictions\n",
    "    # equals to the ground-truth.\n",
    "    correct += (pred == labels).sum()\n",
    "\n",
    "print('Accuracy on testset = {:.2%}'.format(correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that's slightly better than random guessing, which is 10% accuracy (randomly picking a class out of 10 classes). Seems like the network learnt something.\n",
    "\n",
    "Hmmm, what are the classes that performed well, and the classes that did not perform well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correct_class = torch.zeros(10)\n",
    "total_class = torch.zeros(10)\n",
    "\n",
    "for data in testset:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, pred = torch.max(outputs.data, dim=1)\n",
    "    correct = (pred == labels).squeeze()\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        correct_class[label] += correct[i]\n",
    "        total_class[label] += 1\n",
    "\n",
    "# Calculate accuracy and sort in descending order\n",
    "accuracy = correct_class / total_class\n",
    "accuracy, _ = torch.sort(accuracy, descending=True)\n",
    "\n",
    "for i, acc in enumerate(accuracy):\n",
    "    print(f'Accuracy of {classes[i]} \\t = {acc:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
